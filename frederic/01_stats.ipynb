{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN0gajhr7pKd"
   },
   "source": [
    "# Basic statistics for the COVID19 IIPC collection.\n",
    "\n",
    "In this notebook we'll do some basic and descriptives statistics around the files we got from the COVID19 IIPC collection.\n",
    "\n",
    "It is based on and inpspired by the [original code from Nick Ruest and the Archive Unleashed team](https://github.com/archivesunleashed/notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OctPUqrG-K2W"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "In this section, we don't download the data, as it is too big. The data we are using should have been download prior and stored, in *.gz* files in a directory called 'data' which is in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aw-HRGPhdKuk"
   },
   "source": [
    "Unzip the data. We unzip them here, as there seem to be a bug in macOS when you use the Apple provided tools. If it's already unzipped, it will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VouhvD2bEBXf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gunzip: data/audio-information.csv: unknown suffix -- ignored\n",
      "gunzip: data/domain-frequency.csv: unknown suffix -- ignored\n",
      "gunzip: data/domain-graph.csv: unknown suffix -- ignored\n",
      "gunzip: data/image-graph.csv: unknown suffix -- ignored\n",
      "gunzip: data/image-information.csv: unknown suffix -- ignored\n",
      "gunzip: data/pdf-information.csv: unknown suffix -- ignored\n",
      "gunzip: data/powerpoint-information.csv: unknown suffix -- ignored\n",
      "gunzip: data/spreadsheet-information.csv: unknown suffix -- ignored\n",
      "gunzip: data/twitter_crawls_by.csv: unknown suffix -- ignored\n",
      "gunzip: data/video-information.csv: unknown suffix -- ignored\n",
      "gunzip: data/web-graph.csv: unknown suffix -- ignored\n",
      "gunzip: data/web-pages-en.csv: unknown suffix -- ignored\n",
      "gunzip: data/web-pages-fr.csv: unknown suffix -- ignored\n",
      "gunzip: data/web-pages.csv: unknown suffix -- ignored\n",
      "gunzip: data/word-document-information.csv: unknown suffix -- ignored\n"
     ]
    }
   ],
   "source": [
    "!gunzip data/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3Nr_JCbsWx8"
   },
   "source": [
    "Let's check our `data` directory, and make sure they've downloaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RK74TCSuIXE",
    "outputId": "9f2cefc4-d90e-4a5f-8072-516a8b3d8daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-information.csv\n",
      "domain-frequency.csv\n",
      "domain-graph.csv\n",
      "image-graph.csv\n",
      "image-information.csv\n",
      "pdf-information.csv\n",
      "powerpoint-information.csv\n",
      "spreadsheet-information.csv\n",
      "twitter_crawls_by.csv\n",
      "video-information.csv\n",
      "web-graph.csv\n",
      "web-pages-en.csv\n",
      "web-pages-fr.csv\n",
      "web-pages.csv\n",
      "word-document-information.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -1 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS0T6i4xPTVx"
   },
   "source": [
    "# Environment\n",
    "\n",
    "Next, we'll setup our environment so we can load our derivatives into [pandas](https://pandas.pydata.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFAFb2X3_VJC"
   },
   "source": [
    "# Loading our ARCH Datasets as DataFrames\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Next, we'll setup our datasets as pandas DataFrames to work with, and show a preview of each using the Data Table Display.\n",
    "\n",
    "Each block of derivative commands create a variable. That variable is a DataFrame with all of the information from a given derivative. After the DataFrame is created, a preview of it is shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIq6rwtwb64d"
   },
   "source": [
    "## Collection\n",
    "\n",
    "A basic overview of the collection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndZjsWKzUykd"
   },
   "source": [
    "### Domain Frequency\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* domain\n",
    "* count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "id": "xUebRBMHuoRs",
    "outputId": "f345582a-63b2-4b1c-ee25-99dfd6e15b9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>212409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook.com</td>\n",
       "      <td>146781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>75608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coronavirus.rutgers.edu</td>\n",
       "      <td>70082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accounts.google.com</td>\n",
       "      <td>68489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161752</th>\n",
       "      <td>scripts.neemu.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161753</th>\n",
       "      <td>salisburyhospicecharity.org.uk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161754</th>\n",
       "      <td>gbgh.on.ca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161755</th>\n",
       "      <td>gida-global.org</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161756</th>\n",
       "      <td>gadgetsin.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161757 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                domain   count\n",
       "0                          twitter.com  212409\n",
       "1                         facebook.com  146781\n",
       "2                          youtube.com   75608\n",
       "3              coronavirus.rutgers.edu   70082\n",
       "4                  accounts.google.com   68489\n",
       "...                                ...     ...\n",
       "161752               scripts.neemu.com       1\n",
       "161753  salisburyhospicecharity.org.uk       1\n",
       "161754                      gbgh.on.ca       1\n",
       "161755                 gida-global.org       1\n",
       "161756                   gadgetsin.com       1\n",
       "\n",
       "[161757 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_frequency = pd.read_csv(\"data/domain-frequency.csv\")\n",
    "domain_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iox32X1fdYly"
   },
   "source": [
    "## Network\n",
    "These derivative files provide network graph data for analysis, and offer an opportunity to explore the way websites link to each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtA20Erpdhna"
   },
   "source": [
    "### Domain Graph\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* source domain\n",
    "* target domain\n",
    "* count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "qrJHET-odk5Y",
    "outputId": "30dfdd68-8494-4ce1-d903-ccf58291ca6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200606</td>\n",
       "      <td>moph.gov.lb</td>\n",
       "      <td>moph.gov.lb</td>\n",
       "      <td>2180467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210201</td>\n",
       "      <td>moph.gov.lb</td>\n",
       "      <td>moph.gov.lb</td>\n",
       "      <td>2140771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20201225</td>\n",
       "      <td>inumeraveis.com.br</td>\n",
       "      <td>inumeraveis.com.br</td>\n",
       "      <td>1880103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200607</td>\n",
       "      <td>moph.gov.lb</td>\n",
       "      <td>moph.gov.lb</td>\n",
       "      <td>1876804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200224</td>\n",
       "      <td>ecdc.europa.eu</td>\n",
       "      <td>ecdc.europa.eu</td>\n",
       "      <td>1839273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283987</th>\n",
       "      <td>20200409</td>\n",
       "      <td>harfordcountyhealth.com</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283988</th>\n",
       "      <td>20200328</td>\n",
       "      <td>pressherald.com</td>\n",
       "      <td>homes.pressherald.com</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283989</th>\n",
       "      <td>20200408</td>\n",
       "      <td>clarin.com</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283990</th>\n",
       "      <td>20200314</td>\n",
       "      <td>newsroom.arlingtonva.us</td>\n",
       "      <td>departments.arlingtonva.us</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283991</th>\n",
       "      <td>20200221</td>\n",
       "      <td>nonio.net</td>\n",
       "      <td>tvi.iol.pt</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2283992 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         crawl_date                   source                      target  \\\n",
       "0          20200606              moph.gov.lb                 moph.gov.lb   \n",
       "1          20210201              moph.gov.lb                 moph.gov.lb   \n",
       "2          20201225       inumeraveis.com.br          inumeraveis.com.br   \n",
       "3          20200607              moph.gov.lb                 moph.gov.lb   \n",
       "4          20200224           ecdc.europa.eu              ecdc.europa.eu   \n",
       "...             ...                      ...                         ...   \n",
       "2283987    20200409  harfordcountyhealth.com                     npr.org   \n",
       "2283988    20200328          pressherald.com       homes.pressherald.com   \n",
       "2283989    20200408               clarin.com                facebook.com   \n",
       "2283990    20200314  newsroom.arlingtonva.us  departments.arlingtonva.us   \n",
       "2283991    20200221                nonio.net                  tvi.iol.pt   \n",
       "\n",
       "           count  \n",
       "0        2180467  \n",
       "1        2140771  \n",
       "2        1880103  \n",
       "3        1876804  \n",
       "4        1839273  \n",
       "...          ...  \n",
       "2283987        6  \n",
       "2283988        6  \n",
       "2283989        6  \n",
       "2283990        6  \n",
       "2283991        6  \n",
       "\n",
       "[2283992 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_graph = pd.read_csv(\"data/domain-graph.csv\")\n",
    "domain_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3MBHq88dlZ2"
   },
   "source": [
    "### Image Graph\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* source of the image (where it was hosted)\n",
    "* the URL of the image\n",
    "* the alternative text of the image\n",
    "\n",
    "**Due to the size of the graph, this will take time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "AojTsVrfdn9n",
    "outputId": "2d1d5f03-06d1-4f51-9f65-25ae40e87516"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frederic.clavert/opt/anaconda3/envs/awac2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (0,1,2,3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>alt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200309</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/inde...</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/imag...</td>\n",
       "      <td>3D illustration of the novel coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200309</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/inde...</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/imag...</td>\n",
       "      <td>Woman holding a tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200309</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/inde...</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/imag...</td>\n",
       "      <td>world map showing novel coronavirus cases per ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200309</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/inde...</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/imag...</td>\n",
       "      <td>Jet airplane flying above the clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200309</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/inde...</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/imag...</td>\n",
       "      <td>3D Illustration of 2019-nCoV virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66789123</th>\n",
       "      <td>20200421</td>\n",
       "      <td>https://www.isciii.es/QueHacemos/Financiacion/...</td>\n",
       "      <td>https://www.isciii.es/Style%20Library/ISCIII.P...</td>\n",
       "      <td>Logo del gobierno de España - Instituto Carlos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66789124</th>\n",
       "      <td>20200421</td>\n",
       "      <td>https://www.isciii.es/QueHacemos/Financiacion/...</td>\n",
       "      <td>https://www.isciii.es/QueHacemos/Financiacion/...</td>\n",
       "      <td>Logo FEDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66789125</th>\n",
       "      <td>20200421</td>\n",
       "      <td>https://www.isciii.es/QueHacemos/Financiacion/...</td>\n",
       "      <td>https://www.isciii.es/_layouts/15/images/icpdf...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66789126</th>\n",
       "      <td>20200421</td>\n",
       "      <td>https://www.isciii.es/QueHacemos/Financiacion/...</td>\n",
       "      <td>https://www.isciii.es/Style%20Library/ISCIII.P...</td>\n",
       "      <td>Imprimir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66789127</th>\n",
       "      <td>20200421</td>\n",
       "      <td>https://www.isciii.es/QueHacemos/Financiacion/...</td>\n",
       "      <td>https://www.isciii.es/Style%20Library/ISCIII.P...</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66789128 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         crawl_date                                             source  \\\n",
       "0          20200309  https://www.cdc.gov/coronavirus/2019-ncov/inde...   \n",
       "1          20200309  https://www.cdc.gov/coronavirus/2019-ncov/inde...   \n",
       "2          20200309  https://www.cdc.gov/coronavirus/2019-ncov/inde...   \n",
       "3          20200309  https://www.cdc.gov/coronavirus/2019-ncov/inde...   \n",
       "4          20200309  https://www.cdc.gov/coronavirus/2019-ncov/inde...   \n",
       "...             ...                                                ...   \n",
       "66789123   20200421  https://www.isciii.es/QueHacemos/Financiacion/...   \n",
       "66789124   20200421  https://www.isciii.es/QueHacemos/Financiacion/...   \n",
       "66789125   20200421  https://www.isciii.es/QueHacemos/Financiacion/...   \n",
       "66789126   20200421  https://www.isciii.es/QueHacemos/Financiacion/...   \n",
       "66789127   20200421  https://www.isciii.es/QueHacemos/Financiacion/...   \n",
       "\n",
       "                                                        url  \\\n",
       "0         https://www.cdc.gov/coronavirus/2019-ncov/imag...   \n",
       "1         https://www.cdc.gov/coronavirus/2019-ncov/imag...   \n",
       "2         https://www.cdc.gov/coronavirus/2019-ncov/imag...   \n",
       "3         https://www.cdc.gov/coronavirus/2019-ncov/imag...   \n",
       "4         https://www.cdc.gov/coronavirus/2019-ncov/imag...   \n",
       "...                                                     ...   \n",
       "66789123  https://www.isciii.es/Style%20Library/ISCIII.P...   \n",
       "66789124  https://www.isciii.es/QueHacemos/Financiacion/...   \n",
       "66789125  https://www.isciii.es/_layouts/15/images/icpdf...   \n",
       "66789126  https://www.isciii.es/Style%20Library/ISCIII.P...   \n",
       "66789127  https://www.isciii.es/Style%20Library/ISCIII.P...   \n",
       "\n",
       "                                                   alt_text  \n",
       "0                  3D illustration of the novel coronavirus  \n",
       "1                                    Woman holding a tissue  \n",
       "2         world map showing novel coronavirus cases per ...  \n",
       "3                      Jet airplane flying above the clouds  \n",
       "4                        3D Illustration of 2019-nCoV virus  \n",
       "...                                                     ...  \n",
       "66789123  Logo del gobierno de España - Instituto Carlos...  \n",
       "66789124                                         Logo FEDER  \n",
       "66789125                                                NaN  \n",
       "66789126                                           Imprimir  \n",
       "66789127                                                  *  \n",
       "\n",
       "[66789128 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_graph = pd.read_csv(\"data/image-graph.csv\")\n",
    "image_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijcDwS7tdpoG"
   },
   "source": [
    "### Web Graph\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* source\n",
    "* target\n",
    "* anchor text\n",
    "\n",
    "Note that this contains all links and is not aggregated into domains.\n",
    "\n",
    "**Due to the size of the graph, this will take time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9lm4jpumdpwU",
    "outputId": "e22b87fb-8a3a-4055-a3d8-84bd1928ea66"
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 4 fields in line 531516047, saw 14\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/90/j99p488148vcmjxgs16_mq0j42556r/T/ipykernel_2656/364345516.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweb_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/web-graph.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mweb_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/awac2/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/awac2/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/awac2/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/awac2/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/awac2/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/awac2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/awac2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/awac2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/awac2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 4 fields in line 531516047, saw 14\n"
     ]
    }
   ],
   "source": [
    "web_graph = pd.read_csv(\"data/web-graph.csv\")\n",
    "web_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxZdqW7LbF8R"
   },
   "source": [
    "## File Formats\n",
    "\n",
    "These derivatives contain information on certain types of binary files found within a web archive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtqbBhf-bHpR"
   },
   "source": [
    "### Audio\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* URL of the audio file\n",
    "* filename\n",
    "* audio extension\n",
    "* MIME type as provided by the web server\n",
    "* MIME type as detected by Apache TIKA\n",
    "* audio MD5 hash\n",
    "* audio SHA1 hash\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "id": "oNk44pMZcSip",
    "outputId": "4934dd07-cebe-46ad-ccce-05fc9900ed0a"
   },
   "outputs": [],
   "source": [
    "audio = pd.read_csv(\"data/audio-information.csv\")\n",
    "audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnEntLU0U2ox"
   },
   "source": [
    "### Images\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* URL of the image\n",
    "* filename\n",
    "* image extension\n",
    "* MIME type as provided by the web server\n",
    "* MIME type as detected by Apache TIKA\n",
    "* image width\n",
    "* image height\n",
    "* image MD5 hash\n",
    "* image SHA1 hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "GhE_Vhv8Awkx",
    "outputId": "7be5489a-c718-4845-fc70-b6cf42b66c04"
   },
   "outputs": [],
   "source": [
    "images = pd.read_csv(\"data/image-information.csv\")\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6USg-a-Rcaod"
   },
   "source": [
    "### PDFs\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* URL of the PDF file\n",
    "* filename\n",
    "* PDF extension\n",
    "* MIME type as provided by the web server\n",
    "* MIME type as detected by Apache TIKA\n",
    "* PDF MD5 hash\n",
    "* PDF SHA1 hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "Nmjfux3ucayR",
    "outputId": "a00bbeac-20d9-4138-9cff-490fa658db3a"
   },
   "outputs": [],
   "source": [
    "pdf = pd.read_csv(\"data/pdf-information.csv\")\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owAkSikAcrvU"
   },
   "source": [
    "### PowerPoint (all software types) information\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* URL of a PowerPoint or similar file\n",
    "* filename\n",
    "* PowerPoint or similar file extension\n",
    "* MIME type as provided by the web server\n",
    "* MIME type as detected by Apache TIKA\n",
    "* PowerPoint or similar file MD5 hash\n",
    "* PowerPoint or similar file SHA1 hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "-Y0kGxvycvtN",
    "outputId": "621ba6b0-bdf3-4aa5-f998-e524fe118fa2"
   },
   "outputs": [],
   "source": [
    "powerpoint = pd.read_csv(\"data/powerpoint-information.csv\")\n",
    "powerpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOhl9xqOc1tq"
   },
   "source": [
    "### Spreadsheets\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* URL of the spreadsheet file\n",
    "* filename\n",
    "* spreadsheet extension\n",
    "* MIME type as provided by the web server\n",
    "* MIME type as detected by Apache TIKA\n",
    "* spreadsheet MD5 hash\n",
    "* spreadsheet SHA1 hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "-9MXi7g0c2BS",
    "outputId": "7710bca9-ea3b-4e5d-f93a-ed190cf42477"
   },
   "outputs": [],
   "source": [
    "spreadsheet = pd.read_csv(\"data/spreadsheet-information.csv\")\n",
    "spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmJP4rckdBq4"
   },
   "source": [
    "### Videos\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* URL of the video file\n",
    "* filename\n",
    "* video extension\n",
    "* MIME type as provided by the web server\n",
    "* MIME type as detected by Apache TIKA\n",
    "* video MD5 hash\n",
    "* video SHA1 hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "id": "mKHMh6M-dB0J",
    "outputId": "d3cfa40a-35e0-4b15-a4bb-be06f6326d43"
   },
   "outputs": [],
   "source": [
    "video = pd.read_csv(\"data/video-information.csv\")\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3uYwccVdIqR"
   },
   "source": [
    "### Word Documents (all software types)\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* URL of the word document or similar file\n",
    "* filename\n",
    "* word document or similar file extension\n",
    "* MIME type as provided by the web server\n",
    "* MIME type as detected by Apache TIKA\n",
    "* word document or similar file MD5 hash\n",
    "* word document or similar file SHA1 hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "id": "pXuBAaNzdIzc",
    "outputId": "675a3507-4702-4c54-e405-bd0254f43023"
   },
   "outputs": [],
   "source": [
    "word = pd.read_csv(\"data/word-document-information.csv\")\n",
    "word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuzuazApycSu"
   },
   "source": [
    "## Text\n",
    "\n",
    "This derivative provides access to the \"plain text\" of a collection, extracted from web page HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GTL6VtBydje"
   },
   "source": [
    "### Web Pages\n",
    "\n",
    "Provides the following columns:\n",
    "\n",
    "* crawl date\n",
    "* web domain\n",
    "* URL\n",
    "* MIME type as provided by the web server\n",
    "* MIME type as detected by Apache TIKA\n",
    "* content (HTTP headers and HTML removed)\n",
    "\n",
    "**This file is HUGE! Here, limited to the first 1000 non-header rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "jH5fqM9Tyfj7",
    "outputId": "02183875-fde4-4dc0-8f70-6d6c112ed13e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "web_pages = pd.read_csv(\"data/web-pages-FR.csv\")\n",
    "web_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_pages.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(web_pages.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot-table to know how many times a domain has been crawl by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_web_pages = web_pages.groupby(by=['domain','crawl_date'], as_index=False).agg({'crawl_date': pd.Series.nunique})\n",
    "groupby_web_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HPwOCNAvqMe"
   },
   "source": [
    "# Data Analysis\n",
    "\n",
    "Now that we have all of our datasets loaded up, we can begin to work with them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6Pkg0prv3BE"
   },
   "source": [
    "## Counting total files, and unique files\n",
    "\n",
    "Let's take a quick look at how to count items in DataFrames, and use total and unique files as an example to work with.\n",
    "\n",
    "It's definitely work checking out the [pandas documentation](https://pandas.pydata.org/docs/index.html). There are a lot of good examples available, along with a robust [API reference](https://pandas.pydata.org/docs/reference/index.html#api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFX4Gl3wv7bi"
   },
   "source": [
    "\n",
    "#### How many images are in this collection?\n",
    "\n",
    "We can take our `images` variable try a couple of functions to get the same answer.\n",
    "\n",
    "1.   `len(images.index)`\n",
    "  * Get the length of the DataFrame's index.\n",
    "2.   `images.shape[0]`\n",
    "  * Get the shape or dimensionality of the DataFrame, and take the first item in the tuple.\n",
    "3.  `images.count()`\n",
    "  * Count the number of rows for each column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTv8Oet3jiTH",
    "outputId": "b3c5db59-0920-4f4b-c838-efb55c36fe91"
   },
   "outputs": [],
   "source": [
    "len(images.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6rYEERnTjifk",
    "outputId": "68d7d3c4-49e6-416d-a0c2-f05db1e53cb6"
   },
   "outputs": [],
   "source": [
    "images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bn-1v127aKIG",
    "outputId": "3c248b21-ac6c-4cc5-ead5-db0b71efed50"
   },
   "outputs": [],
   "source": [
    "images.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38veKiPhwKo4"
   },
   "source": [
    " #### How many unique images are in the collection?\n",
    "\n",
    " We can see if an image is unique or not by computing an [MD5 hash](https://en.wikipedia.org/wiki/MD5#MD5_hashes) of it, and comparing them. The exact same image might have a filename of `example.jpg` or `foo.jpg`. If the hash is computed for each, we can see that even with different file names, they are actually the same image. So, since we have both a `MD5` and `SHA1` hash column available in our DataFrame, we can just find the unique values, and count them!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WesM3kQowM5B",
    "outputId": "645d661a-b0a1-4cb9-af66-47df5d1b97a7"
   },
   "outputs": [],
   "source": [
    "len(images.md5.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIXkI0-1wWQf"
   },
   "source": [
    "#### What are the top 10 most occurring images in the collection?\n",
    "\n",
    "Here we can take advantage of [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html) to provide us with a list of MD5 hashes, and their respective counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Ts03OFyjPIM",
    "outputId": "bf9870c7-40e5-474c-b38a-d35aa4a4c3f6"
   },
   "outputs": [],
   "source": [
    "images[\"md5\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FG7pGZUEwlaI"
   },
   "source": [
    "\n",
    "#### What's the information around all of the occurances of `d89746888da2d9510b64a9f031eaecd5`?\n",
    "\n",
    "What, you mean you don't know what `d89746888da2d9510b64a9f031eaecd5` means? \n",
    "\n",
    "Let's find those images in the DataFrame. We can here see some of the filenames used, it's dimensions, and it's URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "id": "msmmm65lkSIK",
    "outputId": "e9227287-108a-4d53-8a24-91bf1a665647"
   },
   "outputs": [],
   "source": [
    "images.loc[images[\"md5\"] == \"d89746888da2d9510b64a9f031eaecd5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kE-8epARIG0-"
   },
   "source": [
    "### What does `377d257f2d2e294916143c069141c1c5` look like?\n",
    "\n",
    "Let's grab the live web URL for the image, and then see if we can display it in a markdown cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wB3VqcmgJQM0",
    "outputId": "67a36914-60fe-485e-c592-a1b777c5925a"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None\n",
    "one_image = images.loc[images[\"md5\"] == \"377d257f2d2e294916143c069141c1c5\"].head(1)\n",
    "one_image[\"url\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YV2u_8aLEJS"
   },
   "source": [
    "![377d257f2d2e294916143c069141c1c5](https://analytics.twitter.com/i/adsct?txn_id=l4o6d&p_id=Twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YfsUGSRt1Ns"
   },
   "source": [
    "Well, yes, this is a transparent GIF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrDaY-C8iwhl"
   },
   "source": [
    "\n",
    "Another point of examination with the `images` DataFrame is the `height` and `width` columns. You could take a look at the largest images, or even `0x0` images, and potentially `spacer.gif` occurrences!\n",
    "\n",
    "* “[The invention and dissemination of the spacer gif: implications for the future of access and use of web archives](https://link.springer.com/article/10.1007/s42803-019-00006-8)”\n",
    "* \"[GeoCities and the spacer.gif](https://ruebot.net/post/geocities-and-the-spacer-gif/)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbLLZW2awzCv"
   },
   "source": [
    "#### What are the top 10 most occuring filenames in the collection?\n",
    "\n",
    "Note that this is of course different than the MD5 results up above. Here we are focusing _just_ on filename. So `cover.jpg` for example, might actually be referring to different images who happen to have the same name.\n",
    "\n",
    "Here we can use `value_counts()` again, but this time we'll create a variable for the top filenames so we can use it later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQaw54ACkwdZ",
    "outputId": "ff03cbcc-6886-4b74-fc62-8a821598f9cf"
   },
   "outputs": [],
   "source": [
    "top_filenames = images[\"filename\"].value_counts().head(10)\n",
    "top_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7F3re20BQRI"
   },
   "source": [
    "#### Let's create our first graph!\n",
    "\n",
    "We'll plot the data first with pandas [plot](https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html) functionality, and then plot the data with [Altair](https://altair-viz.github.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "id": "sRvlstfsBWEZ",
    "outputId": "f984304d-1e05-488b-9fa8-09024970ae98"
   },
   "outputs": [],
   "source": [
    "top_filenames_chart = top_filenames.plot.bar(figsize=(25, 10))\n",
    "\n",
    "top_filenames_chart.set_title(\"Top Filenames\", fontsize=22)\n",
    "top_filenames_chart.set_xlabel(\"Filename\", fontsize=20)\n",
    "top_filenames_chart.set_ylabel(\"Count\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQgeOObvgLvK"
   },
   "source": [
    "Now let's setup Altair, and plot the data with Altair. Altair is useful for creating vizualization since they can be easily exported as a PNG or SVG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7Z4J6qjWaVM"
   },
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "id": "s0xwvILYWkgg",
    "outputId": "6d8f7eb2-63d1-4a8d-ed13-532396b4996c"
   },
   "outputs": [],
   "source": [
    "top_filenames_altair = (\n",
    "    images[\"filename\"]\n",
    "    .value_counts()\n",
    "    .head(10)\n",
    "    .rename_axis(\"Filename\")\n",
    "    .reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "filenames_bar = (\n",
    "    alt.Chart(top_filenames_altair)\n",
    "    .mark_bar()\n",
    "    .encode(x=alt.X(\"Filename:O\", sort=\"-y\"), y=alt.Y(\"Count:Q\"))\n",
    ")\n",
    "\n",
    "filenames_rule = (\n",
    "    alt.Chart(top_filenames_altair).mark_rule(color=\"red\").encode(y=\"mean(Count):Q\")\n",
    ")\n",
    "\n",
    "\n",
    "filenames_text = filenames_bar.mark_text(align=\"center\", baseline=\"bottom\").encode(\n",
    "    text=\"Count:Q\"\n",
    ")\n",
    "\n",
    "(filenames_bar + filenames_rule + filenames_text).properties(\n",
    "    width=1400, height=700, title=\"Top Filenames\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BneaN9cgGoly"
   },
   "source": [
    "#### How about a file format distribution?\n",
    "\n",
    "What _kind_ of image files are present? We can discover this by checking their \"media type\", or [MIME type](https://en.wikipedia.org/wiki/Media_type). \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "id": "RDd-J8D-GwDk",
    "outputId": "589699f2-77f7-4323-998e-a82517181e7f"
   },
   "outputs": [],
   "source": [
    "image_mime_types = (\n",
    "    images[\"mime_type_tika\"]\n",
    "    .value_counts()\n",
    "    .head(5)\n",
    "    .rename_axis(\"MIME Type\")\n",
    "    .reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "image_mimes_bar = (\n",
    "    alt.Chart(image_mime_types)\n",
    "    .mark_bar()\n",
    "    .encode(x=alt.X(\"MIME Type:O\", sort=\"-y\"), y=alt.Y(\"Count:Q\"))\n",
    ")\n",
    "\n",
    "image_mime_rule = (\n",
    "    alt.Chart(image_mime_types).mark_rule(color=\"red\").encode(y=\"mean(Count):Q\")\n",
    ")\n",
    "\n",
    "image_mime_text = image_mimes_bar.mark_text(align=\"center\", baseline=\"bottom\").encode(\n",
    "    text=\"Count:Q\"\n",
    ")\n",
    "\n",
    "(image_mimes_bar + image_mime_rule + image_mime_text).properties(\n",
    "    width=1400, height=700, title=\"Image File Format Distribution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKqzuDVz-GiF"
   },
   "source": [
    "## Let's take a look at the domain frequency derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGHnjGRQPzqV"
   },
   "source": [
    "#### What does the distribution of domains look like?\n",
    "\n",
    "Here we can see which domains are the most frequent within the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "C_X_YSD4PyQi",
    "outputId": "3e3deab3-ed7e-4415-8eaf-1117b3756c68"
   },
   "outputs": [],
   "source": [
    "top_domains = domain_frequency.sort_values(\"count\", ascending=False).head(10)\n",
    "\n",
    "top_domains_bar = (\n",
    "    alt.Chart(top_domains)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\"domain:O\", title=\"Domain\", sort=\"-y\"),\n",
    "        y=alt.Y(\"count:Q\", title=\"Count, Mean of Count\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "top_domains_rule = (\n",
    "    alt.Chart(top_domains).mark_rule(color=\"red\").encode(y=\"mean(count):Q\")\n",
    ")\n",
    "\n",
    "top_domains_text = top_domains_bar.mark_text(align=\"center\", baseline=\"bottom\").encode(\n",
    "    text=\"count:Q\"\n",
    ")\n",
    "\n",
    "(top_domains_bar + top_domains_rule + top_domains_text).properties(\n",
    "    width=1400, height=700, title=\"Domains Distribution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDXDhqCcyyFj"
   },
   "source": [
    "### Top Level Domain Analysis\n",
    "\n",
    "pandas allows you to create new columns in a DataFrame based off of existing data. This comes in handy for a number of use cases with the available data that we have. In this case, let's create a new column, `tld`, which is based off an existing column, 'domain'. This example should provide you with an implementation pattern for expanding on these datasets to do further research and analysis.\n",
    "\n",
    "A [top-level domain](https://en.wikipedia.org/wiki/Top-level_domain) refers to the highest domain in an address - i.e. `.ca`, `.com`, `.org`, or yes, even `.pizza`.\n",
    "\n",
    "Things get a bit complicated, however, in some national TLDs. While `qc.ca` (the domain for Quebec) isn't really a top-level domain, it has many of the features of one as people can directly register under it. Below, we'll use the command `suffix` to include this. \n",
    "\n",
    "> You can learn more about suffixes at https://publicsuffix.org.\n",
    "\n",
    "We'll take the `domain` column and extract the `tld` from it with [`tldextract`](https://github.com/john-kurkowski/tldextract).\n",
    "\n",
    "First we'll add the [`tldextract`](https://github.com/john-kurkowski/tldextract) library to the notebook. Then, we'll create the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clPJuQAe5mcg"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "id": "mv7a-MLIx-3f",
    "outputId": "cd120ca9-39f4-4294-a00f-e466539907ee"
   },
   "outputs": [],
   "source": [
    "import tldextract\n",
    "\n",
    "domain_frequency[\"tld\"] = domain_frequency.apply(\n",
    "    lambda row: tldextract.extract(row.domain).suffix, axis=1\n",
    ")\n",
    "domain_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdXFS2yu8XYG"
   },
   "source": [
    "#### Next, let's count the distict TLDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lViQIU48e-u",
    "outputId": "caf97710-ff09-4bcf-fdd9-9e1c93af34e4"
   },
   "outputs": [],
   "source": [
    "tld_count = domain_frequency[\"tld\"].value_counts()\n",
    "tld_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm_V_0PGzZut"
   },
   "source": [
    "#### Next, we'll plot the TLD count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 804
    },
    "id": "N8yNlOa-zmBD",
    "outputId": "eb39d031-d35b-44de-a4c9-47472940f421"
   },
   "outputs": [],
   "source": [
    "tld_count = (\n",
    "    domain_frequency[\"tld\"]\n",
    "    .value_counts()\n",
    "    .rename_axis(\"TLD\")\n",
    "    .reset_index(name=\"Count\")\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "tld_bar = (\n",
    "    alt.Chart(tld_count)\n",
    "    .mark_bar()\n",
    "    .encode(x=alt.X(\"TLD:O\", sort=\"-y\"), y=alt.Y(\"Count:Q\"))\n",
    ")\n",
    "\n",
    "tld_rule = alt.Chart(tld_count).mark_rule(color=\"red\").encode(y=\"mean(Count):Q\")\n",
    "\n",
    "tld_text = tld_bar.mark_text(align=\"center\", baseline=\"bottom\").encode(text=\"Count:Q\")\n",
    "\n",
    "(tld_bar + tld_rule + tld_text).properties(\n",
    "    width=1400, height=700, title=\"Top Level Domain Distribution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLriRk2UFlFP"
   },
   "source": [
    "## Web Crawl Frequency\n",
    "\n",
    "Let's see what the crawl frequency looks like by examining the `web_pages` DataFrame. First we'll create a new DataFrame by extracting the `crawl_date` and `domain` columns, and count the occurances of each domain and date combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "id": "_gGjFO6DAOYT",
    "outputId": "e594cbae-d664-4d55-ec53-227173d71708"
   },
   "outputs": [],
   "source": [
    "crawl_sites = web_pages[[\"crawl_date\", \"domain\"]]\n",
    "crawl_sites = crawl_sites.value_counts().reset_index()\n",
    "crawl_sites.columns = [\"Date\", \"Site\", \"Count\"]\n",
    "crawl_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCJLNokxGaBk"
   },
   "source": [
    "Next, we'll create a stacked bar chart where each bar will show the distribution of pages in that crawl by top-level domain.\n",
    "\n",
    "**NOTE**: Charts like this one work a lot better with collections that have more than 1 or 2 crawl dates. The temporal aspect is definitely something to take into consideration with each of the examples provided in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "xQAx6JpNDL-I",
    "outputId": "dd292885-30a0-463a-93d7-9edf5fd95677"
   },
   "outputs": [],
   "source": [
    "## Altair has a default limit of 5000 rows, and this DataFrame is ~7700 rows, so we're going to disable the max allowed rows.\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "crawl_chart = (\n",
    "    alt.Chart(crawl_sites)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=\"Date:O\",\n",
    "        y=\"Count:Q\",\n",
    "        color=\"Site\",\n",
    "        tooltip=\"Site\",\n",
    "        order=alt.Order(\"Site\", sort=\"descending\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "crawl_chart.properties(width=1400, height=700, title=\"Web Crawl Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "arch-example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
